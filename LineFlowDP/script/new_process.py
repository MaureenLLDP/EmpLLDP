import os
import numpy as np
import torch
from torch_geometric.data import Data

# é…ç½®åŒº ==============================================
DATA_ROOT = './data/'  # æ•°æ®æ ¹ç›®å½•
REQUIRED_FILES = [  # å¿…é¡»åŒ…å«çš„æ–‡ä»¶åç¼€
    '_A.txt',
    '_edge_labels.txt',
    '_graph_indicator.txt',
    '_graph_labels.txt',
    '_node_attributes.txt',
    '_node_labels.txt'
]


# =====================================================

def validate_file_structure(project, version):
    """ä¸¥æ ¼æ ¡éªŒæ–‡ä»¶ç»“æ„"""
    raw_path = os.path.join(DATA_ROOT, project, version, 'raw')
    missing = [f"{version}{suffix}" for suffix in REQUIRED_FILES if not os.path.exists(os.path.join(raw_path, f"{version}{suffix}"))]

    if missing:
        print(f"âŒ ç¼ºå¤±æ–‡ä»¶ ({len(missing)} ä¸ª): {missing}")
        return False
    return True


def load_data_file(project, version, suffix, dtype=torch.float, delimiter=','):
    """å®‰å…¨åŠ è½½ .txt æ–‡ä»¶"""
    path = os.path.join(DATA_ROOT, project, version, 'raw', f"{version}{suffix}")

    try:
        array = np.loadtxt(path, delimiter=delimiter, ndmin=2)
        # å…³é”®ä¿®å¤ï¼šå°†1-basedç´¢å¼•è½¬ä¸º0-based
        if suffix in ['_A.txt', '_graph_indicator.txt']:
            array -= 1  # èŠ‚ç‚¹ç¼–å·ä»0å¼€å§‹
        return torch.tensor(array, dtype=dtype)
    except Exception as e:
        raise RuntimeError(f"åŠ è½½ {os.path.basename(path)} å¤±è´¥: {e}")


def reindex_edge_index(edge_index, graph_indicator, graph_id):
    """é‡æ–°ç´¢å¼• edge_indexï¼Œä½¿å…¶å˜ä¸ºå±€éƒ¨ç´¢å¼•"""
    node_mask = (graph_indicator == graph_id)  # è¯¥å›¾çš„æ‰€æœ‰èŠ‚ç‚¹
    node_indices = torch.nonzero(node_mask).squeeze()
    num_nodes = node_indices.shape[0]

    if num_nodes == 0:
        return torch.empty((2, 0), dtype=torch.long)  # æ— è¾¹ï¼Œè¿”å›ç©º edge_index

    # åˆ›å»ºå…¨å±€ç´¢å¼•åˆ°å±€éƒ¨ç´¢å¼•çš„æ˜ å°„
    reindex_map = {int(node_indices[i]): i for i in range(len(node_indices))}

    # è¿‡æ»¤è¾¹ï¼Œåªä¿ç•™å½“å‰å›¾çš„èŠ‚ç‚¹
    edge_mask = node_mask[edge_index[0]] & node_mask[edge_index[1]]
    edge_index = edge_index[:, edge_mask]  # ä»…ä¿ç•™å±äºå½“å‰å›¾çš„è¾¹

    if edge_index.shape[1] == 0:
        return torch.empty((2, 0), dtype=torch.long)  # æ— è¾¹ï¼Œè¿”å›ç©º edge_index

    # é‡æ–°æ˜ å°„ edge_index
    edge_index = torch.tensor([[reindex_map[int(src)], reindex_map[int(dst)]]
                               for src, dst in edge_index.t().tolist()], dtype=torch.long).t()

    return edge_index


def process_project(project, versions):
    """å¤„ç†å•ä¸ªé¡¹ç›®çš„æ‰€æœ‰ç‰ˆæœ¬"""
    print(f"\nğŸ” å¼€å§‹å¤„ç†é¡¹ç›®: {project}")

    total = 0
    for ver in versions:
        print(f"\nğŸ”„ å¤„ç†ç‰ˆæœ¬: {ver}")

        # æ ¡éªŒæ–‡ä»¶ç»“æ„
        if not validate_file_structure(project, ver):
            continue

        try:
            # åŠ è½½æ‰€æœ‰å¿…è¦æ–‡ä»¶
            edge_index = load_data_file(project, ver, '_A.txt', torch.long, ',').t().contiguous()
            edge_labels = load_data_file(project, ver, '_edge_labels.txt', torch.long)
            graph_indicator = load_data_file(project, ver, '_graph_indicator.txt', torch.long).squeeze()
            graph_labels = load_data_file(project, ver, '_graph_labels.txt', torch.long)
            node_attrs = load_data_file(project, ver, '_node_attributes.txt')
            node_labels = load_data_file(project, ver, '_node_labels.txt', torch.long)

            # å¤„ç†å›¾æ•°æ®
            data_list = []
            for graph_id in torch.unique(graph_indicator):
                node_mask = (graph_indicator == graph_id)
                edge_index_graph = reindex_edge_index(edge_index, graph_indicator, graph_id)

                # è¿‡æ»¤ edge_attrï¼Œä»…ä¿ç•™å½“å‰å›¾çš„è¾¹ç‰¹å¾
                edge_attr_graph = edge_labels[edge_index_graph[0]] if edge_labels is not None else None

                data = Data(
                    x=node_attrs[node_mask],
                    y=graph_labels[graph_id],
                    edge_index=edge_index_graph,
                    edge_attr=edge_attr_graph,
                    node_label=node_labels[node_mask]
                )
                data_list.append(data)

            if edge_index_graph.numel() == 0:
                print(f"âš ï¸ å›¾ {graph_id.item()} æ²¡æœ‰è¾¹ï¼è·³è¿‡ min/max è®¡ç®—")
            else:
                print(f"âœ… å›¾ {graph_id.item()} å¤„ç†å®Œæˆ: èŠ‚ç‚¹={node_attrs[node_mask].shape[0]}, "
                      f"è¾¹={edge_index_graph.shape[1]}, edge_index èŒƒå›´=[{edge_index_graph.min().item()}, {edge_index_graph.max().item()}]")

            # ä¿å­˜ç»“æœ
            save_dir = os.path.join(DATA_ROOT, project, ver, 'processed')
            os.makedirs(save_dir, exist_ok=True)
            torch.save(data_list, os.path.join(save_dir, 'data.pt'))
            print(f"âœ… æˆåŠŸä¿å­˜ {len(data_list)} ä¸ªå›¾æ•°æ®")
            total += len(data_list)

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")

    return total


if __name__ == "__main__":
    # é¡¹ç›®é…ç½®ï¼ˆç‰ˆæœ¬å‚æ•°ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼‰
    all_releases = {
        "activemq": ["activemq-5.0.0", "activemq-5.1.0", "activemq-5.2.0", "activemq-5.3.0", "activemq-5.8.0"],
        "camel": ["camel-1.4.0", "camel-2.9.0", "camel-2.10.0", "camel-2.11.0"],
        "derby": ["derby-10.2.1.6", "derby-10.3.1.4", "derby-10.5.1.1"]
    }

    total = 0
    for project, versions in all_releases.items():
        total += process_project(project, versions)

    print(f"\nğŸ å¤„ç†å®Œæˆï¼å…±å¤„ç† {total} ä¸ªå›¾")
